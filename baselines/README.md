# Baselines of the Metric Track

List of useful repositories for automatic dialogue evaluation
- https://github.com/Maluuba/nlg-eval
- https://github.com/ZHAOTING/dialog-processing
- https://github.com/Shikib/usr
- https://github.com/li3cmz/GRADE
- https://github.com/exe1023/DialEvalMetrics
- https://github.com/Shikib/fed
- https://github.com/James-Yip/QuantiDCE
- https://github.com/alexzhou907/dialogue_evaluation
- https://github.com/e0397123/D-score
- https://github.com/e0397123/DynaEval
- https://github.com/Tiiiger/bert_score
- https://github.com/google-research/bleurt
- https://github.com/facebookresearch/online_dialog_eval
- https://github.com/prakharguptaz/multirefeval
- https://github.com/PlusLabNLP/PredictiveEngagement
- https://github.com/harsh19/Diverse-Reference-Augmentation/
- https://github.com/prakharguptaz/multirefeval

For comprehensive surveys, please refer to:
- [Survey on evaluation methods for dialogue systems](https://link.springer.com/article/10.1007/s10462-020-09866-x)
